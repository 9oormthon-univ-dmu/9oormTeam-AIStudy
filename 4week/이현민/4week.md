# 4 Week

## 4주차 6-1,6-2. TorchVision + DataLoader(Fashion-Mnist&DataLoader/nn.Flatten&DataLoader for mini-batch)

### 강의 키워드: TorchVision, DataLoader, nn.Module, Model Training, CrossEntropyLoss, Accuracy

### 6-1-1 데이터 준비

- **데이터셋 로딩**: 
  PyTorch의 `torchvision.datasets`를 활용하여 FashionMNIST 데이터셋을 로드합니다. 이 데이터셋은 28x28 크기의 흑백 이미지로 구성되어 있으며, 10개의 클래스(옷 종류)로 분류됩니다. 훈련용 데이터와 테스트 데이터를 각각 `train=True` 및 `train=False` 설정으로 로딩합니다. FashionMNIST는 PyTorch에서 제공하는 대표적인 예제 데이터셋 중 하나입니다.
  
- **DataLoader 사용**: 
  PyTorch의 `DataLoader`는 데이터셋을 미니 배치 단위로 나누어 학습할 수 있도록 도와줍니다. `DataLoader`를 사용하여 배치 크기를 설정하고, 데이터셋을 섞을지 여부를 결정하는 등의 작업을 수행합니다. 이때 `shuffle=True`로 설정하면 학습 시 매번 데이터가 섞여서 모델이 데이터를 고르게 학습할 수 있습니다.
  
- **데이터 전처리**:
  데이터 전처리에는 `transforms.ToTensor()`를 사용하여 이미지 데이터를 텐서(tensor) 형식으로 변환합니다. 이미지 데이터는 [0, 255] 범위의 픽셀 값을 갖지만, 텐서로 변환 후 [0, 1] 범위로 정규화됩니다. 이 변환은 신경망 모델이 안정적으로 학습할 수 있도록 도와줍니다.

### 6-1-2 모델 생성

- **모델 정의**: 
  `nn.Module`을 상속받아 다층 신경망을 정의합니다. 이 신경망은 입력층, 은닉층, 그리고 출력층으로 구성되며, 각 층은 완전 연결층(`nn.Linear`)으로 구성됩니다. FashionMNIST 데이터셋은 28x28 크기의 이미지이므로, 입력층은 784개의 뉴런(28x28 = 784)을 가집니다. 출력층은 10개의 클래스로 분류해야 하므로, 10개의 뉴런을 가집니다. 은닉층은 임의의 크기와 활성화 함수(ReLU)를 사용해 정의할 수 있습니다.
  
- **활성화 함수**: 
  은닉층에서 비선형성을 도입하기 위해 `ReLU`(Rectified Linear Unit) 활성화 함수를 사용합니다. `ReLU`는 음수를 0으로 변환하고, 양수는 그대로 전달하는 함수로, 딥러닝 모델에서 매우 자주 사용됩니다.

- **손실 함수 및 옵티마이저**: 
  분류 문제이므로 손실 함수로 `CrossEntropyLoss`를 사용합니다. 이 함수는 내부적으로 소프트맥스(Softmax)를 포함하고 있어 출력층에서의 확률 분포를 계산한 후 손실을 측정합니다. 최적화 알고리즘으로는 `Adam` 옵티마이저를 사용합니다. `Adam`은 학습 속도를 빠르게 하면서도 안정적인 결과를 제공하는 최적화 알고리즘입니다.

### 6-1-3 모델 학습

- **모델 학습**:
  학습 단계에서는 `train_loader`에서 배치 단위로 데이터를 불러와 모델에 입력한 후, 순전파(forward pass)를 통해 예측값을 얻습니다. 그 후 손실 함수를 사용해 손실을 계산하고, 역전파(backward pass)를 통해 기울기를 계산한 다음 옵티마이저를 사용해 모델의 파라미터를 업데이트합니다. 이 과정은 여러 에포크(epoch)에 걸쳐 반복되며, 각 에포크마다 손실 값이 감소하는지 모니터링합니다.

- **정확도 계산**: 
  `torchmetrics.Accuracy`를 사용하여 학습 중 정확도를 계산합니다. `Accuracy` 클래스는 예측한 결과와 실제 레이블을 비교하여 정확도를 반환해주며, 정확도는 학습의 중요한 지표로 사용됩니다. 정확도를 모니터링하여 모델이 잘 학습되고 있는지 확인할 수 있습니다.

### 6-1-4 모델 평가 및 시각화

- **모델 평가**:
  테스트 데이터셋을 사용하여 학습된 모델을 평가합니다. 평가 시에는 `torch.no_grad()` 또는 `with torch.inference_mode()`를 사용하여 기울기 계산을 하지 않고, 순전파 계산만 수행합니다. 이 모드는 메모리 사용량을 줄이고, 계산 속도를 높이는 데 유리합니다. 테스트 데이터에 대한 예측값을 구한 후, 모델의 정확도를 계산합니다.

- **이미지 시각화**: 
  학습된 모델이 예측한 결과를 시각적으로 확인하기 위해 Matplotlib을 사용합니다. 테스트 데이터에서 몇 가지 샘플을 선택하고, 각 샘플의 실제 레이블과 모델의 예측 결과를 나란히 비교해 볼 수 있습니다. 이를 통해 모델의 예측이 얼마나 정확한지, 특정 클래스에서 잘못된 예측을 하는지 여부를 시각적으로 확인할 수 있습니다.
