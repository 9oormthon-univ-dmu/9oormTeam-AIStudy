## 2주차 - 차근차근 PyTorch & TorchVision - MLOps를 위한 모델 실험 추적 & 모델 웹앱 배포까지

## 4.1. Multi-class Classification 1 - nn.CrossEntropyLoss

### 강의 키워드
Multi-class Classification, softmax(), argmax(), nn.CrossEntropyLoss

### 강의내용
### 다중 클래스 분류 개요

다중 클래스 분류 문제를 해결하기 위해서는 **Softmax**, **Argmax**, 및 **Cross-Entropy Loss**를 사용합니다. 이들 각각의 역할과 사용법을 아래에 설명합니다.

#### 1. Softmax 함수

- **역할**: 모델의 출력(logits)을 각 클래스에 대한 확률 분포로 변환합니다.
- **작동 원리**: 각 클래스의 점수를 지수 함수에 통과시킨 후, 이 점수들을 정규화하여 전체 확률의 합이 1이 되도록 만듭니다.
- **사용 예시**:
  ```python
  probabilities = torch.softmax(logits, dim=1)
  ```

#### 2. Argmax 함수

- **역할**: Softmax를 통해 얻은 클래스 확률 중에서 가장 높은 확률을 가진 클래스의 인덱스를 찾습니다.
- **작동 원리**: 확률 벡터에서 가장 큰 값을 가진 인덱스를 반환하여 예측된 클래스를 결정합니다.
- **사용 예시**:
  ```python
  predicted_classes = torch.argmax(probabilities, dim=1)
  ```

#### 3. Cross-Entropy Loss

- **정의**: 실제 클래스와 모델이 예측한 클래스 확률 간의 차이를 측정하는 손실 함수입니다.
- **작동 원리**: 실제 클래스의 확률을 1로, 나머지 클래스는 0으로 가정하여 모델의 예측 확률과의 차이를 계산합니다. 이는 예측이 얼마나 실제와 가까운지를 측정합니다.
- **사용 예시**:
  ```python
  import torch.nn as nn

  # 손실 함수 정의
  loss_fn = nn.CrossEntropyLoss()

  # 손실 계산
  loss = loss_fn(logits, true_labels)
  ```

#### 모델 훈련 시 사용 방법

1. **훈련 시**:
   - 모델의 출력(logits)에 대해 **Softmax**를 적용하여 클래스 확률을 계산합니다.
   - **Cross-Entropy Loss**를 사용하여 예측 확률과 실제 라벨 간의 손실을 평가합니다.

2. **평가 시**:
   - 예측된 확률 분포에서 **Argmax**를 적용하여 최종 예측 클래스를 결정합니다.

```python
# 모델의 출력 logits
logits = model(inputs)

# 소프트맥스를 적용하여 클래스 확률을 계산하여 가장 높은 확률을 가진 클래스의 인덱스를 찾는다.
predicted_classes = torch.softmax(logits, dim=1).argmax(dim=1) #  logits -> predicted probs -> predicted class nums

# Cross-Entropy Loss 계산
loss_fn = nn.CrossEntropyLoss()
loss = loss_fn(logits, true_labels) # logits는 raw output, true_labels는 실제 라벨
```


## 4.2. Multi-class Classification 2 - TorchMetrics & Non-linearity

### 강의 키워드
Multi-class Classification, TorchMetrics, Accuracy

### 강의내용
`torchmetrics`는 PyTorch 모델의 성능을 평가하기 위한 다양한 메트릭을 제공합니다. 다중 클래스 분류 문제에서 유용하게 사용되는 메트릭에는 `Accuracy`, `Precision`, `Recall`, 그리고 `F1Score`가 있습니다.
### torchmetrics
- **`torchmetrics`**: PyTorch의 성능 평가 메트릭을 제공하는 라이브러리로, 다양한 성능 지표를 쉽게 계산할 수 있습니다.

#### Accuracy

- **역할**: 전체 샘플 중 올바르게 분류된 샘플의 비율을 계산합니다.
- **사용법**: `Accuracy`는 `task="multiclass"`와 `num_classes`를 매개변수로 받아야 합니다. 이는 다중 클래스 분류 문제에서 정확도를 올바르게 계산하기 위해 필수적입니다.
-     (강의의 코드는 예전 버전이라서 Accuracy()로 썼지만 최근 버전에서는 task나 num_classes를 따로 지정해주지 않으면 오류가 났습니다.)
- **예시**:
  ```python
  from torchmetrics import Accuracy
  
  num_classes = 4
  accuracy_metric = Accuracy(task="multiclass", num_classes=num_classes).to(device)
  accuracy = accuracy_metric(y_predicted, y_test.to(device)).item()  # Scalar tensor -> Plain number
  print("Accuracy:", accuracy)
  ```

-  Precision: 각 클래스별로 정확도를 계산하고, 전체 평균을 제공합니다. 특정 클래스에 대한 예측이 얼마나 정확한지를 나타냅니다.

-  Recall: 각 클래스별로 재현율을 계산하고, 전체 평균을 제공합니다. 특정 클래스가 얼마나 잘 포착되었는지를 나타냅니다.

- F1 Score: Precision과 Recall의 조화 평균으로, 클래스의 성능을 종합적으로 평가합니다. Precision과 Recall의 균형을 잡아주는 지표입니다.

#### 코드 예시
다중 클래스 분류 문제에서 `Accuracy`, `Precision`, `Recall`, `F1Score`를 계산하는 코드 예시는 다음과 같습니다:

```python
from torchmetrics import Accuracy, Precision, Recall, F1Score

num_classes = 4

for metric_class in [Accuracy, Precision, Recall, F1Score]:
    metric = metric_class(task="multiclass", num_classes=num_classes).to(device)
    result = metric(y_predicted, y_test.to(device)).item()  # Scalar tensor -> Plain number
    
    print(metric.__class__.__name__, ":", result)
```


## 5.1. Classification & Regression 요약 1 - Classification (Titanic)

### 강의 키워드
Classification, Titanic dataset

### 강의내용
타이타닉 데이터로 분류모델을 만들어 학습 시키고 데이터 시각화를 하였습니다.
강의 내용 중 데이터 타입에 따라 다르게 쓰는 손실함수가 기억에 남아 정리했습니다.
### BCEWithLogitsLoss vs CrossEntropyLoss

#### BCEWithLogitsLoss

- **기능 설명**: 
  - `BCEWithLogitsLoss`는 이진 분류 문제를 위해 설계된 손실 함수입니다.
  - 이 함수는 `sigmoid` 활성화 함수와 `binary cross-entropy` 손실을 결합하여 계산합니다.
  - 로지스틱 회귀의 출력을 시그모이드 함수로 변환하고, 이진 교차 엔트로피 손실을 계산합니다.

- **사용 예시**: 
  - **이진 분류**: 이메일 스팸 필터링, 질병 유무 예측 등
  - **코드 예시**:
    ```python
    import torch
    import torch.nn as nn
    
    criterion = nn.BCEWithLogitsLoss()
    
    # 예시 데이터 (배치 크기 3, 출력 클래스 1)
    y_pred = torch.tensor([[0.5], [1.2], [-0.3]], dtype=torch.float32)
    y_true = torch.tensor([[0], [1], [0]], dtype=torch.float32)
    
    loss = criterion(y_pred, y_true)
    print("BCEWithLogitsLoss:", loss.item())
    ```

#### CrossEntropyLoss

- **기능 설명**:
  - `CrossEntropyLoss`는 다중 클래스 분류 문제를 위한 손실 함수입니다.
  - 이 함수는 `softmax` 활성화 함수와 `categorical cross-entropy` 손실을 결합하여 계산합니다.
  - 모델의 로짓 출력을 소프트맥스 함수로 변환하고, 목표 클래스와의 교차 엔트로피를 계산합니다.

- **사용 예시**:
  - **다중 클래스 분류**: 이미지 분류, 뉴스 기사 주제 분류 등
  - **코드 예시**:
    ```python
    import torch
    import torch.nn as nn
    
    criterion = nn.CrossEntropyLoss()
    
    # 예시 데이터 (배치 크기 3, 클래스 수 4)
    y_pred = torch.tensor([[1.2, 0.3, -1.5, 0.7],
                           [0.3, 1.5, -0.4, 0.2],
                           [-0.6, 1.0, 0.1, -0.5]], dtype=torch.float32)
    y_true = torch.tensor([0, 1, 2], dtype=torch.long)  # 정수 형태의 클래스 레이블
    
    loss = criterion(y_pred, y_true)
    print("CrossEntropyLoss:", loss.item())
    ```



## 5.2. Classification & Regression 요약 2 - Regression (Boston house price)

### 강의 키워드
Regression, California Housing Dataset
### 강의내용
보스턴 집 값 데이터를 활용하여 회귀 분석 모델링을 만들고 학습 시키는 강의였습니다.
데이터 로딩 및 전처리를 할 때 load_boston 데이터를 강의에서 사용하는데 현재는 scikit-learn에서 1.2버전 이후에 제거된 데이터라는 것을 알았습니다.
load_boston dataset은 특정 인종의 분리 거주가 주택 가격에 긍정적인 영향을 미친다는 비윤리적인 가정을 기반을 만들어진 데이터라서 윤리적인 이유로 삭제되었고 
데이터를 모을 때의 가정과 연구의 목적을 제대로 설정해야지 사용할 수 있는 데이터라는 것을 배웠습니다.
그래서 5.2강의는는 캘리포니아 주택 데이터셋으로 대체하여 실습했습니다. 
기존 데이터와 다른 형태의 데이터를 실습하면서 x_data.shape의 형태가 (20640, 8)로 나왔기 떄문에 모델링을 할 떄 num_features도 8로 줘야한다는 것을 배웠습니다.
