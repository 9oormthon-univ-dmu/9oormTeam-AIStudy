## 5주차 - 차근차근 PyTorch & TorchVision - MLOps를 위한 모델 실험 추적 & 모델 웹앱 배포까지

## 7-1 CNN with ImageFolder DataLoader1,2

### 강의 키워드

### 강의내용
이번 강의는 CNN으로 사진 종류 구분하는 모델을 만듭니다.
추석 연휴 이후로 오랜만에 하는 모델링 작업이라 전체적으로 정리해보았습니다.

### 1.Prepare the dataset(Food-101 일부 사용)
>1) zipfile를 통해 파일에 있는 zip을 읽고 사용할 폴더를 조회한다.
>2) 사용할 폴더를 train과 test폴더로 나눈다.
>3) 그 안에 있는 jpg로 끝나는 파일을 glob으로 찾은 후 train_images에 넣는다.
```python
import zipfile
import os
import glob

#1) zipfile를 통해 파일에 있는 zip을 읽고 사용할 폴더를 조회한다.
with zipfile.ZipFile("data_food101/Food101.zip", "r") as zip_f:
    
    print("Unzipping the dataset.") 
    
    zip_f.extractall("data_food101/data") # "extract" "all" files

for dir_path, dir_names, file_names in os.walk("data_food101/data"): # 지정된 디렉토리 내부를 거닐며("walk") 조회
    
    if len(dir_names) == 3:
        print('--------------------------------')
    
    print("There are {} directories and {} images in '{}'.".format(len(dir_names), len(file_names), dir_path))

#2) 사용할 폴더를 train과 test폴더로 나눈다.
TRAIN_DIR = "data_food101/data/train"
TEST_DIR  = "data_food101/data/test"

#3) 그 안에 있는 jpg로 끝나는 파일을 glob으로 찾은 후 train_images에 넣는다.
train_images = glob.glob("data_food101/data/train/*/*.jpg")
```

### 2. Prepare the DataLoader - Using [torchvision.datasets.ImageFolder]
>1) 이미지의 크기를 Resize로 수정하고 데이터 유형을 ToTensor로 pixel값을 PyTorch tensor로 바꿉니다.
 ```python
from torchvision import transforms

# torchvision.transforms.ToTensor()는 pixel 값들을 [ 0~255 ] 에서 [ 0.0~1.0 ]으로 자동 변환합니다. @ https://bit.ly/3gpqIn0

IMG_TRANSFORM = transforms.Compose([ # "구성하다"(compose)
    
    transforms.Resize(size=(64, 64)), # image resize
    transforms.ToTensor() # (Original) PIL format -> PyTorch tensors 

])
```
>2) image directories를 ImageFolder로 만듭니다.
```python
from torchvision.datasets import ImageFolder

train_imgfolder = ImageFolder(root=TRAIN_DIR,
                              transform=IMG_TRANSFORM, # torchvision.transforms.Compose
                              target_transform=None)   # we can transform labels, too (if it is needed)

test_imgfolder  = ImageFolder(root=TEST_DIR,
                              transform=IMG_TRANSFORM)

print(train_imgfolder, '\n')
print(test_imgfolder)
```
>3) 이미지 폴더를 DataLoader에 올려 mini baches로 나눕니다.
```python
from torch.utils.data import DataLoader

torch.manual_seed(42)

train_dataloader = DataLoader(dataset=train_imgfolder, 
                              batch_size=32, 
                              num_workers=os.cpu_count(), # number of subprocesses to use for data loading
                              shuffle=True)

test_dataloader  = DataLoader(dataset=test_imgfolder, 
                              batch_size=32, 
                              num_workers=os.cpu_count(), 
                              shuffle=False) # 테스트 데이터는 shuffling할 필요가 없습니다.

# A set of batch-data

batch_x, batch_y = next(iter(train_dataloader))
```
### 3.Build the model 
데이터 없이 CNN 구축,(딥러닝 같은 경우엔 중요 process를 짠 후, 그 뒤에 데이터를 입힌다.)
> 데이터 증강을 통해 과적합을 방지하기 위해 self.conv_block_entrance에 층층히 이미지 변형을 합니다.
```python
class CNN_TinyVGG(nn.Module): # should inherit the class nn.Module
    
    
    def __init__(self, num_channels, num_filters, num_classes): 
        
        super().__init__()
        
        #이미지 데이터가 들어오는 입구
        self.conv_block_entrance = nn.Sequential( # Create a sequential model
            
            # Convolution-layer
            nn.Conv2d(in_channels=num_channels, # will be '3' == R/G/B
                      out_channels=num_filters, # num_filters == num of feature-maps == num of output channels
                      kernel_size=(3, 3), 
                      stride=1,     # default
                      padding=1),   # 0 == 'valid', 1 == 'same' 
            nn.ReLU(),
            
            # Convolution-layer
            nn.Conv2d(in_channels=num_filters,  # should be same as the number of "channels of previous output"
                      out_channels=num_filters,
                      kernel_size=(3, 3),
                      stride=1,
                      padding=1),
            nn.ReLU(),
            
            # Pooling-layer
            nn.MaxPool2d(kernel_size=2, stride=2) # 2x2 풀링을 사용해 입력 크기를 절반으로 줄입니다.
        )
        # [ 32, 3, 64, 64 ] -> [ 32, 10, 32, 32 ]
        
        # 데이터를 더 깊게 학습시키기 위한 층
        self.conv_block_within = nn.Sequential(
            nn.Conv2d(num_filters, num_filters, (3, 3), padding=1),
            nn.ReLU(),
            nn.Conv2d(num_filters, num_filters, (3, 3), padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        # [ 32, 10, 32, 32 ] -> [ 32, 10, 16, 16 ]
        
        # 최종적으로 이미지를 분류하는 분류기를 구성하는 층
        self.classifier_block = nn.Sequential(
            nn.Flatten(), # Flatten the input data
            nn.Linear(in_features=num_filters * 16 * 16, 
                      out_features=num_classes)
        )
        # [ 32, 10, 16, 16 ] -> [ 32, 10 * 16 * 16 ] -> [ 32, 10 ]
    
    
    def forward(self, x):
        return self.classifier_block(conv_block_within(conv_block_entrance(x)))
```
### 4.Train thhe model
>1)Initialize the model
```python
torch.manual_seed(42) # "Manually" set the "seed"

model = CNN_TinyVGG(num_channels=3, # R / G / B
                    num_filters=10, # number of filters == number of feature-maps
                    num_classes=3   # Pizza / Steak / Sushi
                   ).to(device)
    
temp_batch_x = next(iter(train_dataloader))[0]

model(temp_batch_x)

```
>2)training을 하기 전에 모델 모델이 잘 돌아가는지 확인합니다.
>3) Make train & test step as separate functions- 실제 데이터를 넣어 모델을 훈련시키고 테스트합니다.
```python
def train_step(model, dataloader, loss_fn, optimizer, metric, device):
    
    # 모델을 training mode로 설정 (default state)
    model.train()
    
    # train-loss & train-accuracy for one epoch
    train_loss = 0
    train_acc  = 0
    
    for batch_idx, (X, y) in enumerate(dataloader): # get an item from DataLoader with it's index number
        
        X = X.to(device)
        y = y.to(device)
        
        # 1. (x 데이터를 모델에 넣고) 순방향 계산 진행 (forward pass)
        logits = model(X)

        # 2. (Batch) Training cost 계산 (Cost function 계산)
        loss = loss_fn(logits, y) # cost of batch <- nn.CrossEntropyLoss() : built-in Softmax
        train_loss += loss.item()
        
        # 3. Optimizer 내부의 이전 gradient 값 초기화 (Make "grad" to "zero")
        optimizer.zero_grad()

        # 4. Back-propagation ("Backward" propagation)
        loss.backward()

        # 5. Gradient descent 진행 (Take a "step" to update parameters)
        optimizer.step()

        # 6. (Batch) Training accuracy 계산 
        predicted_classes = logits.softmax(dim=1).argmax(dim=1)
        train_acc += metric(predicted_classes, y).item() # calculate the batch accuracy & add to the epoch accuracy

    
    # Batch 순회 종료 후
    train_loss = train_loss / len(dataloader) # cost of batches / num of batches (calculate average)
    train_acc  = train_acc  / len(dataloader) # acc  of batches / num of batches (calculate average)
    
    return train_loss, train_acc
```
```python
def test_step(model, dataloader, loss_fn, metric, device):
    
    # 모델을 evaluation mode로 설정
    model.eval() 
    
    # test-loss & test-accuracy for one epoch
    test_loss = 0
    test_acc  = 0
    
    with torch.inference_mode(): # Set "inference mode"
        
        for batch_idx, (X, y) in enumerate(dataloader): # get an item from DataLoader with it's index number
            
            X = X.to(device)
            y = y.to(device)
    
            # 1. (x 데이터를 모델에 넣고) 순방향 계산 진행 (forward pass)
            logits = model(X)

            # 2. (Batch) Test cost 계산 (Cost function 계산)
            loss = loss_fn(logits, y) # cost of batch <- nn.CrossEntropyLoss() : built-in Softmax
            test_loss += loss.item()

            # 3. (Batch) Test accuracy 계산 
            predicted_classes = logits.softmax(dim=1).argmax(dim=1)
            test_acc += metric(predicted_classes, y).item() # calculate the batch accuracy & add to the epoch accuracy

    
    # Batch 순회 종료 후
    test_loss = test_loss / len(dataloader) # cost of batches / num of batches (calculate average)
    test_acc  = test_acc  / len(dataloader) # acc  of batches / num of batches (calculate average)
    
    return test_loss, test_acc
```
4)데이터 더 훈련시키기 - 모델을 여러 epoch 동안 학습시키고, 각 epoch마다 학습과 테스트 데이터를 이용해 손실(loss)과 정확도(accuracy)를 계산하여 출력하고, 그 결과를 저장하는 과정
```python
def train(model, 
          train_dataloader, test_dataloader, 
          optimizer, loss_fn, metric, 
          device, epochs=5):
    
    
    results = {"train_loss": [], 
               "train_acc" : [], 
               "test_loss" : [], 
               "test_acc"  : []}
    
    
    for epoch in tqdm(range(epochs)): # from tqdm.auto import tqdm
        
        train_loss, train_acc = train_step(model=model,
                                           dataloader=train_dataloader,
                                           loss_fn=loss_fn, 
                                           optimizer=optimizer, 
                                           metric=metric, 
                                           device=device)
        
        test_loss, test_acc   = test_step(model=model,
                                          dataloader=test_dataloader, 
                                          loss_fn=loss_fn, 
                                          metric=metric, 
                                          device=device)
        
        
        results["train_loss"].append(train_loss)
        results["train_acc"].append(train_acc)
        results["test_loss"].append(test_loss)
        results["test_acc"].append(test_acc)
        
        
        print('Epoch : {} | Train_loss : {} | Train_acc : {} | Test_loss : {} | Test_acc : {}'.format(epoch+1, 
                                                                                                      train_loss, 
                                                                                                      train_acc, 
                                                                                                      test_loss, 
                                                                                                      test_acc))
    
    return results
```
5)만든 모델을 시간을 제어 각 test에 따라 10번 정도 결과를 확인합니다.
```python
torch.manual_seed(42) 

model = CNN_TinyVGG(num_channels=3, # R / G / B
                    num_filters=10, # number of filters == number of feature-maps
                    num_classes=3   # Pizza / Steak / Sushi <- len(train_data.classes)
                   ).to(device)
loss_fn = nn.CrossEntropyLoss() # Softmax + CrossEntropy (built-in Softmax)

optimizer = torch.optim.Adam(params=model.parameters(), # "parameters" to optimize (apply gradient descent)
                             lr=0.001)                  # "l"earning "r"ate 
    
metric_accuracy = Accuracy(task="multiclass", num_classes=3).to(device) # from torchmetrics import Accuracy

from timeit import default_timer as timer 

START_TIME = timer()

NUM_EPOCHS = 10

model_results = train(model=model, 
                      train_dataloader=train_dataloader,
                      test_dataloader=test_dataloader,
                      optimizer=optimizer,
                      loss_fn=loss_fn, 
                      metric=metric_accuracy,
                      device=device,
                      epochs=NUM_EPOCHS)

END_TIME = timer()
```
